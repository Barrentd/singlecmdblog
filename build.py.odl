#!/usr/bin/env python3
# TinyBlog Pro (stdlib + optional python-markdown/pymdown-extensions)
# - Full Markdown via python-markdown (+pymdownx if available)
# - Fallback tiny parser if deps missing
# - Ordered posts (newâ†’old), sticky navbar (Home/About + category select)
# - In-memory dev server (--serve) and static assets via /assets/
# - Size budget enforced on written HTML files (default 14 KB)

from __future__ import annotations
from pathlib import Path
import json, re, sys, argparse, html, time, datetime as dt, os, importlib.util, mimetypes, shutil
from http.server import BaseHTTPRequestHandler, HTTPServer

# ===================== CLI =====================
def parse_args():
    p = argparse.ArgumentParser(description="TinyBlog static generator")
    p.add_argument("--content", default="content", help="content directory (markdown)")
    p.add_argument("--public",  default="public",  help="static assets dir served at /assets/")
    p.add_argument("--out",     default="build",   help="output directory")
    p.add_argument("--site",    default="site.json", help="site config (title, palette)")
    p.add_argument("--base-url", default="/", help="base URL (e.g. / or /blog/)")
    p.add_argument("--max-bytes", type=int, default=14*1024, help="size budget per HTML file")
    p.add_argument("--serve", action="store_true", help="serve from memory (no files written)")
    p.add_argument("--host", default="127.0.0.1", help="dev server host")
    p.add_argument("--port", type=int, default=8080, help="dev server port")
    return p.parse_args()

# ===================== Markdown engines =====================
def _markdown_engine():
    """Return a callable md(text)->html. Prefer python-markdown (+pymdownx), else fallback."""
    if importlib.util.find_spec("markdown"):
        import markdown  # type: ignore
        exts = [
            "extra",        # tables, fenced_code, footnotes, def_list, attr_list
            "sane_lists",
            "smarty",
            "toc",          # adds ids on headings
            "codehilite",   # graceful w/o pygments
        ]
        # optional pymdownx family
        for name in (
            "pymdownx.tasklist", "pymdownx.tilde", "pymdownx.caret",
            "pymdownx.emoji", "pymdownx.superfences", "pymdownx.highlight"
        ):
            if importlib.util.find_spec(name): exts.append(name)
        md = markdown.Markdown(extensions=exts, extension_configs={
            "pymdownx.tasklist": {"custom_checkbox": True, "clickable_checkbox": False},
            "codehilite": {"guess_lang": False, "noclasses": False},
        })
        return lambda text: md.reset().convert(text)
    # ---- fallback minimal (headings, bold, italic, code, links, hr, paragraphs) ----
    RX_INLINE = [
        (re.compile(r"\*\*(.+?)\*\*"), r"<b>\1</b>"),
        (re.compile(r"\*(.+?)\*"), r"<i>\1</i>"),
        (re.compile(r"`(.+?)`"), lambda m: f"<code>{html.escape(m.group(1))}</code>"),
        (re.compile(r"!\[([^\]]*)\]\(([^)]+)\)"), r'<img alt="\1" src="\2">'),
        (re.compile(r"\[([^\]]+)\]\(([^)]+)\)"), r'<a href="\2">\1</a>'),
    ]
    def _mini(text: str) -> str:
        lines = text.strip().splitlines()
        out, buf = [], []
        def flush():
            if buf:
                t = " ".join(buf).strip()
                if t: out.append(f"<p>{t}</p>")
                buf.clear()
        for raw in lines:
            l = raw.rstrip()
            if not l: flush(); continue
            if l.startswith("# "):  flush(); out.append(f"<h1>{html.escape(l[2:].strip())}</h1>"); continue
            if l.startswith("## "): flush(); out.append(f"<h2>{html.escape(l[3:].strip())}</h2>"); continue
            if l.strip() == "---":  flush(); out.append("<hr>"); continue
            buf.append(html.escape(l))
        flush()
        s = "".join(out)
        for rx, repl in RX_INLINE: s = rx.sub(repl, s)
        return s
    return _mini

md_render = _markdown_engine()

# ===================== Front matter =====================
# YAML-lite front matter:
# ---
# title: My Post
# categories: DevOps, Notes
# date: 2025-08-27
# page: about
# ---
def parse_front_matter(md: str):
    if not md.startswith("---"): return {}, md
    end = md.find("\n---", 3)
    if end == -1: return {}, md
    head = md[3:end].strip(); body = md[end+4:].lstrip("\n")
    meta = {}
    for line in head.splitlines():
        if ":" in line:
            k, v = line.split(":", 1)
            meta[k.strip().lower()] = v.strip()
    if "categories" in meta:
        meta["categories"] = [c.strip() for c in meta["categories"].split(",") if c.strip()]
    return meta, body

def parse_date(s: str) -> dt.datetime | None:
    if not s: return None
    for fmt in ("%Y-%m-%d", "%Y-%m-%d %H:%M", "%Y-%m-%dT%H:%M", "%Y-%m-%dT%H:%M:%S"):
        try: return dt.datetime.strptime(s, fmt)
        except ValueError: pass
    try: return dt.datetime.fromisoformat(s)
    except Exception: return None

# ===================== Template / CSS / minify =====================
BASE_CSS = (
":root{--bg:#fff;--fg:#111;--muted:#666;--link:#0a6cff;--accent:#3b82f6;--card:#f8fafc;--card-border:#e5e7eb}"
"@media(prefers-color-scheme:dark){:root{--bg:#0b0b0c;--fg:#eaeaea;--muted:#9aa0a6;--link:#8ab4f8;--accent:#60a5fa;--card:#0f172a;--card-border:#1f2937}}"
"*,*:before,*:after{box-sizing:border-box}"
"html{font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,'Helvetica Neue',Arial;font-size:16px;-webkit-text-size-adjust:100%}"
"body{margin:0;background:var(--bg);color:var(--fg);line-height:1.5}"
"main{max-width:min(92ch,96vw);margin:0 auto;padding:2.5vh 3vw}"
"h1{font-size:clamp(22px,4.5vw,30px);line-height:1.15;margin:10px 0 6px}"
"h2{font-size:clamp(18px,3.7vw,24px);line-height:1.2;margin:14px 0 8px}"
"p{margin:10px 0}a{color:var(--link);text-decoration:none}a:hover{text-decoration:underline}"
"code,pre{font-family:ui-monospace,SFMono-Regular,Menlo,Consolas,monospace}"
"pre{overflow:auto;padding:10px;border:1px solid var(--card-border);border-radius:8px;background:var(--card)}"
"code{padding:1px 3px;border:1px solid var(--card-border);border-radius:3px;background:rgba(127,127,127,.08)}"
"img{max-width:100%;height:auto;border-radius:6px}"
"table{width:100%;border-collapse:collapse;display:block;overflow-x:auto}"
"th,td{border:1px solid var(--card-border);padding:.4rem .5rem;text-align:left;vertical-align:top}"
"blockquote{border-left:3px solid var(--card-border);margin:.8rem 0;padding:.1rem .8rem;color:var(--muted)}"
"ul,ol{margin:.4rem 0 .6rem .9rem}"
".task-list-item{list-style:none}"
".task-list-item input{margin-right:.5rem}"
"hr{border:0;border-top:1px solid var(--card-border);margin:12px 0}"
"footer{margin-top:16px;font-size:.85rem;opacity:.7}"
"/* navbar */"
".navbar{position:sticky;top:0;z-index:10;background:var(--bg);border-bottom:1px solid var(--card-border);backdrop-filter:saturate(180%) blur(6px)}"
".navwrap{max-width:min(92ch,96vw);margin:0 auto;padding:.6rem 3vw;display:flex;gap:12px;align-items:center}"
".brand{font-weight:700}.navlink{margin-right:10px}.spacer{flex:1}"
".catselect{font:inherit;padding:.35rem .5rem;border:1px solid var(--card-border);border-radius:8px;background:var(--card);color:var(--fg)}"
"/* ordered list */"
".postlist{list-style:decimal inside;margin:0;padding:0}"
".postlist li{margin:.45rem 0;padding:.4rem .6rem;border-radius:8px;background:var(--card);border:1px solid var(--card-border)}"
".posttitle{font-weight:600}.postmeta{display:inline-flex;gap:8px;margin-left:8px;color:var(--muted);font-size:.9rem}"
)

def palette_override(pal: dict[str,str] | None) -> str:
    if not pal: return ""
    k = lambda n, d: pal.get(n, d)
    return (":root{"
            f"--bg:{k('bg','#fff')};--fg:{k('fg','#111')};--muted:{k('muted','#666')};"
            f"--link:{k('link','#0a6cff')};--accent:{k('accent','#3b82f6')};"
            f"--card:{k('card','#f8fafc')};--card-border:{k('cardBorder','#e5e7eb')}"
            "}")

def build_nav(site_title: str, base_url: str, categories_sorted: list[tuple[str,str]], has_about: bool) -> str:
    if categories_sorted:
        opts = "".join(f'<option value="{base_url}category/{slug}.html">{html.escape(name)}</option>'
                       for name, slug in categories_sorted)
        cat_select = (f'<select class="catselect" aria-label="Categories" '
                      f'onchange="if(this.value)location.href=this.value">'
                      f'<option value="">{html.escape("Categories")}</option>'
                      f'<option value="{base_url}index.html">All</option>{opts}</select>')
    else:
        cat_select = ""
    about_link = f'<a class="navlink" href="{base_url}about.html">About</a>' if has_about else ""
    return ('<div class="navbar"><div class="navwrap">'
            f'<a class="brand navlink" href="{base_url}index.html">{html.escape(site_title)}</a>'
            f'<a class="navlink" href="{base_url}index.html">Home</a>'
            f'{about_link}<span class="spacer"></span>{cat_select}'
            '</div></div>')

def render_page(doc_title: str, body_html: str, site_title: str,
                base_url: str, palette_css: str, nav_html: str) -> str:
    return ("<!doctype html><meta charset=utf-8>"
            f"<title>{html.escape(doc_title)}</title>"
            "<meta name=viewport content='width=device-width,initial-scale=1'>"
            "<meta name=generator content=TinyBlog>"
            f"<style>{BASE_CSS}{palette_css}</style>"
            f"{nav_html}<main><header><h1>{html.escape(doc_title)}</h1></header>"
            f"{body_html}<footer></footer></main>")

def minify_html(s: str) -> str:
    s = re.sub(r">\s+<", "><", s)
    s = re.sub(r"\s{2,}", " ", s)
    return s.strip()

# ===================== Helpers =====================
def read_site(site_path: Path) -> dict:
    return json.loads(site_path.read_text(encoding="utf-8")) if site_path.exists() else {"title":"TinyBlog","description":""}

def slugify(s: str) -> str:
    s = s.lower()
    s = re.sub(r"[^a-z0-9]+", "-", s).strip("-")
    return re.sub(r"-{2,}", "-", s) or "uncategorized"

def excerpt_from_md(md: str, limit: int = 160) -> str:
    for line in md.splitlines():
        t = line.strip()
        if not t or t.startswith("#"): continue
        txt = re.sub(r"`(.+?)`", r"\1", t)
        return (txt[:limit] + "â€¦") if len(txt) > limit else txt
    return ""

def collect_entries(content_dir: Path):
    posts, pages = [], {}
    for f in sorted(content_dir.glob("*.md")):
        raw = f.read_text(encoding="utf-8").strip()
        meta, body = parse_front_matter(raw)
        title = meta.get("title") or (body.splitlines()[0].lstrip("# ").strip() if body else f.stem) or f.stem
        page_kind = (meta.get("page") or "").lower()
        is_page = page_kind in ("about", "page") or f.stem.lower() == "about"
        date_obj = parse_date(meta.get("date","")) or dt.datetime.fromtimestamp(f.stat().st_mtime)
        date_str = date_obj.strftime("%Y-%m-%d")
        cats = meta.get("categories") or []
        entry = {
            "slug": f.stem, "title": title, "md": body,
            "categories": cats, "categories_slug": [slugify(c) for c in cats],
            "excerpt": excerpt_from_md(body), "date_obj": date_obj, "date_str": date_str,
        }
        if is_page: pages[f.stem.lower()] = entry
        else: posts.append(entry)
    return posts, pages

def build_ordered_list(items, base_url: str) -> str:
    lis = []
    for p in items:
        chips = " ".join(f'<a class="chip" href="{base_url}category/{slug}.html">{html.escape(name)}</a>'
                         for name, slug in zip(p["categories"], p["categories_slug"]))
        meta = f'<span class="postmeta"><span>{p["date_str"]}</span>{chips}</span>'
        lis.append(f'<li><a class="posttitle" href="{base_url}{p["slug"]}.html">{html.escape(p["title"])}</a>{meta}</li>')
    return '<ol class="postlist">' + "".join(lis) + "</ol>"

def bytes_ok(path: Path, limit: int):
    size = path.stat().st_size
    if size > limit: raise SystemExit(f"[FAIL] {path.name} = {size} bytes > {limit}")
    print(f"[OK]   {path.name} = {size} bytes")

# ===================== In-memory server =====================
class _MemHandler(BaseHTTPRequestHandler):
    pages: dict[str,str] = {}     # route -> html
    public_dir: Path | None = None
    def do_GET(self):
        route = self.path
        if route == "/" or route.endswith("/"): route = "/index.html"
        if route.startswith("//"): route = route[1:]
        # HTML from memory
        page = self.pages.get(route)
        if page is not None:
            self.send_response(200)
            self.send_header("content-type","text/html; charset=utf-8")
            self.send_header("cache-control","no-store, max-age=0")
            self.end_headers(); self.wfile.write(page.encode("utf-8")); return
        # Static /assets/* from disk
        if route.startswith("/assets/") and self.public_dir:
            fs_path = (self.public_dir / route[len("/assets/"):]).resolve()
            if fs_path.is_file() and str(fs_path).startswith(str(self.public_dir.resolve())):
                ctype = mimetypes.guess_type(str(fs_path))[0] or "application/octet-stream"
                self.send_response(200); self.send_header("content-type", ctype)
                self.send_header("cache-control","no-store, max-age=0"); self.end_headers()
                with fs_path.open("rb") as f: shutil.copyfileobj(f, self.wfile)
                return
        self.send_response(404); self.send_header("content-type","text/plain; charset=utf-8")
        self.end_headers(); self.wfile.write(b"404")

# ===================== Build =====================
def build(args):
    root = Path.cwd()
    content_dir = root / args.content
    public_dir  = root / args.public
    out_dir     = root / args.out
    site = read_site(root / args.site)
    pal_css = palette_override(site.get("palette"))

    posts, pages = collect_entries(content_dir)
    posts.sort(key=lambda p: p["date_obj"], reverse=True)

    # categories
    cat_map = {}
    for p in posts:
        if not p["categories"]:
            cat_map.setdefault("uncategorized", ("Uncategorized", []))[1].append(p)
        else:
            for name, slug in zip(p["categories"], p["categories_slug"]):
                cat_map.setdefault(slug, (name, []))[1].append(p)
    categories_sorted = sorted([(v[0], k) for k, v in cat_map.items()], key=lambda x: x[0].lower())

    nav_html = build_nav(site.get("title","TinyBlog"), args.base_url, categories_sorted, has_about=("about" in pages))

    rendered: dict[str, str] = {}
    # index
    idx_body = build_ordered_list(posts, args.base_url)
    rendered["/index.html"] = minify_html(render_page("Home", idx_body, site.get("title","TinyBlog"), args.base_url, pal_css, nav_html))
    # about
    if "about" in pages:
        p = pages["about"]
        rendered["/about.html"] = minify_html(render_page("About", md_render(p["md"]), site.get("title","TinyBlog"), args.base_url, pal_css, nav_html))
    # posts
    for p in posts:
        chips = " ".join(f'<a class="chip" href="{args.base_url}category/{slug}.html">{html.escape(name)}</a>'
                         for name, slug in zip(p["categories"], p["categories_slug"]))
        head = f'<div class="postmeta"><span>{p["date_str"]}</span>{chips}</div>'
        body_html = head + md_render(p["md"])
        rendered[f"/{p['slug']}.html"] = minify_html(render_page(p["title"], body_html, site.get("title","TinyBlog"), args.base_url, pal_css, nav_html))
    # categories
    for slug, (name, plist) in cat_map.items():
        plist_sorted = sorted(plist, key=lambda p: p["date_obj"], reverse=True)
        body = f"<h2>Category: {html.escape(name)}</h2>" + build_ordered_list(plist_sorted, args.base_url)
        rendered[f"/category/{slug}.html"] = minify_html(render_page(f"Category Â· {name}", body, site.get("title","TinyBlog"), args.base_url, pal_css, nav_html))

    if args.serve:
        _MemHandler.pages = rendered
        _MemHandler.public_dir = public_dir if public_dir.exists() else None
        srv = HTTPServer((args.host, args.port), _MemHandler)
        print(f"[SERVE] http://{args.host}:{args.port}  (HTML from memory; static from {public_dir}/ at /assets/)")
        try: srv.serve_forever()
        except KeyboardInterrupt: print("\n[STOP] server stopped"); srv.server_close()
        return

    # write build + copy public assets
    out_dir.mkdir(parents=True, exist_ok=True)
    for route, html_doc in rendered.items():
        out_file = out_dir / route.lstrip("/")
        out_file.parent.mkdir(parents=True, exist_ok=True)
        out_file.write_text(html_doc, encoding="utf-8")
        bytes_ok(out_file, args.max_bytes)
    # copy public -> build/assets
    if public_dir.exists():
        for src in public_dir.rglob("*"):
            if src.is_file():
                rel = src.relative_to(public_dir)
                dst = out_dir / "assets" / rel
                dst.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(src, dst)
    print(f"[DONE] {len(posts)} post(s), {len(cat_map)} category page(s) + index @ {time.strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    build(parse_args())
